{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eBrain examples: vim-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ––  by http://www.ccnlab.net   ––"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how an encoding model can be applied on real data. We use the publically available vim-1 fMRI data set from the Gallant lab. During the experiment single static images have been presented to 2 subjects. \n",
    "\n",
    "The data set is available here: http://crcns.org/data-sets/vc/vim-1\n",
    "Information on the data set: https://crcns.org/files/data/vim-1/crcns-vim-1-readme.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "#Set base directory of your Python modules not contained in \n",
    "#standard module path (i.e. directory where ebrain is): \n",
    "sys.path.append('/home/ed/Documents/Code/PYTHON/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from encoding_model.EncodingModel import EncodingModel\n",
    "import tables\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from the VIM-1 dataset. We choose voxels from the region of interest (ROI) V1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EstimatedResponses = tables.open_file('/home/ed/Documents/Code/PYTHON/ebrain/Data/EstimatedResponses.mat')\n",
    "Stimuli = scipy.io.loadmat('/home/ed/Documents/Code/PYTHON/ebrain/Data/Stimuli.mat',struct_as_record=True)\n",
    "data_train = EstimatedResponses.get_node('/dataTrnS1')[:].astype('float64')\n",
    "data_val = EstimatedResponses.get_node('/dataValS1')[:].astype('float64')\n",
    "ROI = EstimatedResponses.get_node('/roiS1')[:].flatten()\n",
    "V1idx = np.nonzero(ROI==1)[0] #ROI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brain voxels we are interested in are positioned within a 3D matrix. We need to remove every voxel that is not an actual brain voxel (marked by NaNs): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V1resp_train = data_train[:,V1idx]\n",
    "V1resp_val = data_val[:,V1idx]\n",
    "mask = (np.nan_to_num(V1resp_val) != 0 ).all(axis=0) | (np.nan_to_num(V1resp_train) != 0 ).all(axis=0)\n",
    "V1resp_train=V1resp_train[:,mask]\n",
    "V1resp_val=V1resp_val[:,mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only select a random subset of the voxels for this demonstration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding performance:  0.845614232034  (mean R)\n"
     ]
    }
   ],
   "source": [
    "n_vox=V1resp_train.shape[1]   #set to 'V1resp_train.shape[1]' for all\n",
    "np.random.seed(0)\n",
    "target_vox=np.random.randint(n_vox, size=n_vox)\n",
    "V1resp_train=V1resp_train[:,target_vox]\n",
    "V1resp_val=V1resp_val[:,target_vox]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create, fit and predict with an EncodingModel object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define encoding model\n",
    "em=EncodingModel()\n",
    "\n",
    "# Fit encoding model \n",
    "em.fit(stim_train,V1resp_train)\n",
    "\n",
    "# Predict encoding model \n",
    "V1resp_val_hat=em.predict(stim_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Remove all voxels that are not significant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "significant_vox=em.rm.model.H_0==False\n",
    "V1resp_val=V1resp_val[:,np.squeeze(significant_vox)]\n",
    "V1resp_train=V1resp_train[:,np.squeeze(significant_vox)]\n",
    "\n",
    "print '\\nsigfniciant voxels:',n_vox-np.sum(em.rm.model.H_0),'/', n_vox, 'at alpha =',em.rm.model.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can analyze the performance of our encoding model. We calculate the correlations between predictions and the measured responses on our left out validation set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr2_coeff(A,B):\n",
    "    # Rowwise mean of input arrays & subtract from input arrays themeselves\n",
    "    A_mA = A - A.mean(1)[:,None]\n",
    "    B_mB = B - B.mean(1)[:,None]\n",
    "    # Sum of squares across rows\n",
    "    ssA = (A_mA**2).sum(1);\n",
    "    ssB = (B_mB**2).sum(1);\n",
    "    # Finally get corr coeff\n",
    "    return np.dot(A_mA,B_mB.T)/np.sqrt(np.dot(ssA[:,None],ssB[None]))\n",
    "\n",
    "# Get prediction / response voxel correlations\n",
    "R = np.diagonal(corr2_coeff(V1resp_val.T,V1resp_val_hat[0].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize these correlations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if V1resp_val_hat[0].shape[1]==0:\n",
    "    print 'no responses can be predicted at this alpha setting'\n",
    "else:\n",
    "    print 'encoding performance: ',np.mean(R),' (mean R)'\n",
    "    # Plot encoding performance Pyplot \n",
    "    fig = plt.figure()\n",
    "    plt.plot(np.arange(len(R))+1,sorted(R, reverse=True))\n",
    "    fig.suptitle('encoding performance')\n",
    "    plt.xlabel('voxel')\n",
    "    yLab=plt.ylabel('R')\n",
    "    yLab.set_rotation(0)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xscale('log')\n",
    "    \n",
    "# Get identification accuracy\n",
    "dPoints=V1resp_val.shape[0]\n",
    "ranking=np.zeros(dPoints)\n",
    "for i in range(0,dPoints):\n",
    "    C = corr2_coeff (np.expand_dims(V1resp_val_hat[0][i,:],axis=1).T ,  V1resp_val)\n",
    "    ranking[i]=np.sum(C>C[:,i])+1\n",
    "print 'identification performance: ',np.mean(ranking),'/ 120 (mean ranking)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
